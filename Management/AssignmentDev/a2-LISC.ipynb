{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cbcf6d0722b4332d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Assignment 2: Neuroscience Literature Mining\n",
    "\n",
    "This assignment will demonstrate how to pull data from an API, how to work with the [LISC package](https://lisc-tools.github.io/lisc/), and test your knowledge of working with classes and numpy.\n",
    "\n",
    "**PLEASE DO NOT CHANGE THE NAME OF THIS FILE.**\n",
    "\n",
    "**PLEASE DO NOT COPY & PASTE OR DELETE CELLS INCLUDED IN THE ASSIGNMENT.**\n",
    "\n",
    "\n",
    "## Installing LISC on datahub\n",
    "\n",
    "From the datahub ```Files``` browser, you'll see a dropdown menu titles ```New```. From there select ```Terminal```, and that will open a new terminal window.\n",
    "\n",
    "Once in the Terminal, execute the following command:\n",
    "\n",
    "```\n",
    "pip install lisc\n",
    "```\n",
    "\n",
    "This will install the LISC package that you'll be using in this assignment.\n",
    "\n",
    "\n",
    "## How to complete assignments\n",
    "\n",
    "Whenever you see:\n",
    "\n",
    "```\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "```\n",
    "\n",
    "You need to **replace (meaning, delete) these lines of code with code that answers the questions** and meets the specified criteria. Make sure you remove the 'raise' line when you do this (or your notebook will raise an error, regardless of any other code, and thus fail the grading tests).\n",
    "\n",
    "You should write the answer to the questions in those cells (the ones with `# YOUR CODE HERE`), but you can also add extra cells to explore / investigate things if you need / want to. \n",
    "\n",
    "Any cell with `assert` statements in it is a test cell. You should not try to change or delete these cells. Note that there might be more than one assert that tests a particular question. \n",
    "\n",
    "If a test does fail, reading the error that is printed out should let you know which test failed, which may be useful for fixing it.\n",
    "\n",
    "Note that some cells, including the test cells, may be read only, which means they won't let you edit them. If you cannot edit a cell - that is normal, and you shouldn't need to edit that cell.\n",
    "\n",
    "\n",
    "## Tips & Tricks\n",
    "\n",
    "The following are a couple tips & tricks that may help you if you get stuck on anything.\n",
    "\n",
    "#### Printing Variables\n",
    "You can (and should) print and check variables as you go. This allows you to check what values they hold, and fix things if anything unexpected happens.\n",
    "\n",
    "#### Restarting the Kernel\n",
    "- If you run cells out of order, you can end up overwriting things in your namespace. \n",
    "- If things seem to go weird, a good first step is to restart the kernel, which you can do from the kernel menu above.\n",
    "- Even if everything seems to be working, it's a nice check to 'Restart & Run All', to make sure everything runs properly in order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9a80f9f3295cb2ab",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Part 1: Fetching data from URLs\n",
    "\n",
    "In this section we'll show you the very basics of how to look up how many articles are indexed in Pubmed that have specific words or phrases (n-grams) in their titles and/or abstracts.\n",
    "\n",
    "For this example, we begin by counting how many articles have been published whose titles or abstracts contain the phrases \"working memory\" or \"short term memory\". Look through the cell below to get a sense of what it is doing, and then run the cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\\n<!DOCTYPE eSearchResult PUBLIC \"-//NLM//DTD esearch 20060628//EN\" \"https://eutils.ncbi.nlm.nih.gov/eutils/dtd/20060628/esearch.dtd\">\\n<eSearchResult>\\n\\t<Count>46034</Count>\\n</eSearchResult>\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request # default library for requesting data from URLs\n",
    "\n",
    "# this is the base URL for making use of the NIH NLM database search API\n",
    "u_eutils = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi'\n",
    "\n",
    "##### all of the code that follows is to construct the full search URL #####\n",
    "\n",
    "# what database to search; here, pubmed\n",
    "u_db = 'db=pubmed'\n",
    "\n",
    "# what information to return; here, count of the number of articles\n",
    "u_rettype = 'rettype=count'\n",
    "\n",
    "# what field to search; here, tiab (pubmed's code for TItle and ABstract)\n",
    "u_field = 'field=tiab'\n",
    "\n",
    "# what term(s) to search for; here \"working memory\" OR \"short term memory\"\n",
    "# note that the double quotes around the phrases indicate we only want to return\n",
    "    # searches that contain that exact phrase\n",
    "u_term = 'term='\n",
    "url_searchterms = '\"working memory\" OR \"short term memory\"'\n",
    "url_searchterms = url_searchterms.replace(' ', '+') # URLs don't do spaces; replace with +\n",
    "u_term = u_term + url_searchterms\n",
    "\n",
    "# stitch the URL together from the parts we gave it\n",
    "url = u_eutils + '?' + u_db + '&' + u_rettype + '&' + u_field + '&' + u_term\n",
    "\n",
    "##### end URL construction block #####\n",
    "\n",
    "with urllib.request.urlopen(url) as response:\n",
    "    xml = response.read()\n",
    "xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9f9158654e4502e5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q1: Making your own search\n",
    "\n",
    "You can see, between the `<Count>` tags in the long response above, that this returns (on Feb 01, 2022) 46034 articles in Pubmed with the phrases \"working memory\" or \"short term memory\" in their titles and/or abstracts. This number, of course, will keep increasing over time (and might have increased since we released the assignment!).\n",
    "\n",
    "1. Use the eutils documentation, specifically the esearch tools [here](https://www.ncbi.nlm.nih.gov/books/NBK25499/#chapter4.ESearch) and [here](https://www.ncbi.nlm.nih.gov/books/NBK3827/#pubmedhelp.Title_TI), to modify the above code to find the count of how many articles have been published containing any of the following three terms <font color='red'>**in their titles only**</font>:\n",
    "\n",
    "    * dentate gyrus\n",
    "    * entorhinal cortex\n",
    "    * subiculum\n",
    "\n",
    "\n",
    "2. In the cell below the url creation cell (after you've retrieved the xml) create a new variable, `number_of_articles`, that lists that count (as an integer). Remember the double quotes around the phrases, and name the search phrase string `url_searchterms`, just as in the example above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-de51725c9709625a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\\n<!DOCTYPE eSearchResult PUBLIC \"-//NLM//DTD esearch 20060628//EN\" \"https://eutils.ncbi.nlm.nih.gov/eutils/dtd/20060628/esearch.dtd\">\\n<eSearchResult>\\n\\t<Count>5468</Count>\\n</eSearchResult>\\n'\n"
     ]
    }
   ],
   "source": [
    "# Run API query here\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "# this is the base URL for making use of the NIH NLM database search API\n",
    "u_eutils = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi'\n",
    "\n",
    "##### all of the code that follows is to construct the full search URL #####\n",
    "\n",
    "# what database to search; here, pubmed\n",
    "u_db = 'db=pubmed'\n",
    "\n",
    "# what information to return; here, count of the number of articles\n",
    "u_rettype = 'rettype=count'\n",
    "\n",
    "# what field to search; here, title (pubmed's code for title)\n",
    "u_field = 'field='\n",
    "u_field = u_field + 'ti'\n",
    "\n",
    "# what term(s) to search for; here \"working memory\" OR \"short term memory\"\n",
    "# note that the double quotes around the phrases indicate we only want to return\n",
    "    # searches that contain that exact phrase\n",
    "u_term = 'term='\n",
    "url_searchterms = '\"dentate gyrus\" OR \"entorhinal cortex\" OR \"subiculum\"'\n",
    "url_searchterms = url_searchterms.replace(' ', '+') # URLs don't do spaces; replace with +\n",
    "u_term = u_term + url_searchterms\n",
    "\n",
    "url = u_eutils + '?' + u_db + '&' + u_rettype + '&' + u_field + '&' + u_term\n",
    "\n",
    "##### end URL construction block #####\n",
    "\n",
    "with urllib.request.urlopen(url) as response:\n",
    "    xml = response.read()\n",
    "print(xml)\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3963a9249af0b851",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Create number_of_articles here\n",
    "### BEGIN SOLUTION\n",
    "number_of_articles = 5468\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-54c47de7ad67b3af",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Tests for Q1 (worth 5 points)\n",
    "assert isinstance(u_field,str)\n",
    "assert isinstance(url_searchterms,str)\n",
    "assert isinstance(url,str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-96efe836ba4d28aa",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden tests for Q1 (worth 5 points)\n",
    "### BEGIN HIDDEN TESTS\n",
    "assert u_field == 'field=title' or u_field == 'field=ti'\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-91e9689f112f83dc",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden tests for Q1 (worth 5 points)\n",
    "### BEGIN HIDDEN TESTS\n",
    "assert url_searchterms == '\"dentate+gyrus\"+OR+\"entorhinal+cortex\"+OR+\"subiculum\"'\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-7f45cca832af3943",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Additional hidden tests for Q1 (worth 5 points)\n",
    "### BEGIN HIDDEN TESTS\n",
    "wiggle_room = 100\n",
    "assert [(number_of_articles > (number_of_articles-wiggle_room)) \n",
    "        & (number_of_articles < (number_of_articles+wiggle_room))]\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bc8692f4860bde86",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Part 2: Basic literature scanner (LISC) usage\n",
    "\n",
    "Now, instead of all of this manual URL construction, we're going to take advanatage of an open-source toolbox from [Tom Donoghue](https://tomdonoghue.github.io) and [Voytek's lab](https://voyteklab.com) here at UC San Diego called LISC (for LIterature SCanner). It's available for pip install from pypi [here](https://pypi.org/project/lisc/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-829777d33ba816e8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Demonstration of LISC\n",
    "The below cell is all of the LISC imports you'll need.\n",
    "\n",
    "Here, we create a list called <code>terms_a</code>, that contains the same three search terms we used above:\n",
    "\n",
    "* dentate gyrus\n",
    "* entorhinal cortex\n",
    "* subiculum\n",
    "\n",
    "Note the double quotes around the phrases. This time we're passing an argument for field that searches both titles and abstracts (<code>field='tiab'</code>). (Give it a few seconds to run.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running counts for:  \"dentate gyrus\"\n",
      "Running counts for:  \"entorhinal cortex\"\n",
      "Running counts for:  \"subiculum\"\n",
      "The number of documents found for each search term is:\n",
      "  '\"dentate gyrus\"'       -   18338\n",
      "  '\"entorhinal cortex\"'   -    7536\n",
      "  '\"subiculum\"'           -    2968\n"
     ]
    }
   ],
   "source": [
    "from lisc import Counts\n",
    "from lisc.utils.db import SCDB\n",
    "from lisc.plts.counts import *\n",
    "\n",
    "terms_a = [['\"dentate gyrus\"'], ['\"entorhinal cortex\"'], ['\"subiculum\"']]\n",
    "\n",
    "# Initialize counts object and use the add_terms method to add terms that we want to search\n",
    "counts = Counts()\n",
    "counts.add_terms(terms_a)\n",
    "\n",
    "# Collect data using the run_collection method\n",
    "counts.run_collection(verbose=True, db='pubmed', field='tiab')\n",
    "\n",
    "# Check how many articles were found for each search term\n",
    "counts.check_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6773a665f3c4190a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q2\n",
    "`check_counts` is a(n):\n",
    "\n",
    "* `A` attribute of `counts`\n",
    "* `B` method of `counts`\n",
    "* `C` inherited class of `counts`\n",
    "\n",
    "Write your answer below as a new variable, <code>q2_answer</code>. So if the answer was a hypothetical option <code>D</code>, you would write:\n",
    "â€‹\n",
    "<code>q2_answer = 'D'</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-43e81e8682b5c1b3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "q2_answer = 'B'\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ade9472e1101f50f",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Tests for Q2 (worth 5 points)\n",
    "\n",
    "assert isinstance(q2_answer,str)\n",
    "\n",
    "### BEGIN HIDDEN TESTS\n",
    "assert q2_answer == 'B'\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-997da88cf22227bb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q3\n",
    "1. Create a new list called <code>terms_b</code>, that contains the four lobes of the brain: 'frontal lobe', 'temporal lobe', 'parietal lobe', and 'occipital lobe'. Remember the quotes around the phrases. Check the counts for these terms. \n",
    "2. Create a new variable, <code>number_of_lobes_articles</code>, that is equal to the *total* number of articles (as an integer) that mention any of those phrases in their titles or abstracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0cccd1557823b047",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running counts for:  \"frontal lobe\"\n",
      "Running counts for:  \"temporal lobe\"\n",
      "Running counts for:  \"parietal lobe\"\n",
      "Running counts for:  \"occipital lobe\"\n",
      "The number of documents found for each search term is:\n",
      "  '\"frontal lobe\"'     -   20373\n",
      "  '\"temporal lobe\"'    -   34333\n",
      "  '\"parietal lobe\"'    -    8939\n",
      "  '\"occipital lobe\"'   -    6357\n"
     ]
    }
   ],
   "source": [
    "# Run your LISC query here\n",
    "### BEGIN SOLUTION\n",
    "terms_b = [['\"frontal lobe\"'], ['\"temporal lobe\"'], ['\"parietal lobe\"'], ['\"occipital lobe\"']]\n",
    "\n",
    "counts = Counts()\n",
    "counts.add_terms(terms_b)\n",
    "\n",
    "# Collect data\n",
    "counts.run_collection(verbose=True, db='pubmed', field='tiab')\n",
    "\n",
    "# Check how many articles were found for each search term\n",
    "counts.check_counts()\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cd33a4d9813aa339",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Assign number_of_lobes_articles here\n",
    "number_of_lobes_articles = 70002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-7c20250c131d47d4",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Tests for Q3, wroth 5 points\n",
    "assert isinstance(counts,object)\n",
    "assert isinstance(number_of_lobes_articles,int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e84ad3a097c3031e",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden tests, worth 5 points\n",
    "### BEGIN HIDDEN TESTS\n",
    "wiggle_room = 1500\n",
    "assert [(number_of_lobes_articles > (number_of_lobes_articles-wiggle_room)) & \n",
    " (number_of_lobes_articles < (number_of_lobes_articles+wiggle_room))]\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1b57b115e0186b2f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## LISC: Term co-occurances\n",
    "LISC not only finds the counts for each search time, but also runs each pairwise comparison between terms to find how many papers are published that talk about <code>term_i</code> <em>and</em> <code>term_j</code>. This is reported as an array in <code>counts.counts</code> where each <em>i,j</em> index is how many papers are published that mention <code>term_i</code> with <code>term_j</code>.\n",
    "\n",
    "For example, for the four lobes, we get the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5bb8c34dcda206cf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0, 7294, 4261, 2424],\n",
       "       [7294,    0, 4317, 2854],\n",
       "       [4261, 4317,    0, 2193],\n",
       "       [2424, 2854, 2193,    0]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-351b954218abd431",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The top row and left column are co-occurances for the the zeroth item in our list, \"frontal lobe\", with itself and all other terms. You'll note that LISC sets a term as having 0 publications matching with itself, by convention. You see that there are more papers published that mention \"frontal lobe\" with \"temporal lobe\" (>7200 together) than have ever been published about the \"occipital lobe\".\n",
    "\n",
    "An interesting question is whether this is driven by true differences in how those regions are studied, or whether it's an issue of the fact that we are limited by the terminology being used when we get the counts using LISC. For example, neurophysiologists generally don't study the \"occiptal lobe\", rather they focus on subregions (V1, V2), or refer to the cortex specifically using the phase \"occipital cortex\" rather than \"occipital lobe\". One could try to get around this problem by explicitly including all of the subregions of the occipital lobe. Alternatively one could simply search for the more general \"occipital\", to encompass both \"occipital lobe\" and \"occipital cortex\", however this runs into the issue that the medical literature will also include research on the \"occipital bone\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c72a301c42bb36b5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q4\n",
    "Using LISC and the <code>terms_a</code> list, store the <code>counts.counts</code> array as a new variable, <code>cooccurance_matrix</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b832df074d20ae47",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running counts for:  \"dentate gyrus\"\n",
      "Running counts for:  \"entorhinal cortex\"\n",
      "Running counts for:  \"subiculum\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   0, 1428,  837],\n",
       "       [1428,    0,  720],\n",
       "       [ 837,  720,    0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize counts object and add the terms that we want to search\n",
    "counts = Counts()\n",
    "counts.add_terms(terms_a)\n",
    "\n",
    "# Collect data\n",
    "counts.run_collection(verbose=True, db='pubmed', field='tiab')\n",
    "\n",
    "cooccurance_matrix = counts.counts\n",
    "cooccurance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-0e62aed37f8722c7",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Tests for Q4 (worth 5 points)\n",
    "import numpy as np\n",
    "assert isinstance(cooccurance_matrix,np.ndarray)\n",
    "\n",
    "### BEGIN HIDDEN TESTS\n",
    "assert sum(np.diag(cooccurance_matrix)) == 0\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1f2c68a7f9120ef2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q5\n",
    "At this point, you might have noticed that the output of counts is an numpy array. Use the cell below to assign the **shape** of your numpy array to a variable `matrix_shape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8ef3fbc6ecff9b5e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "import numpy as np\n",
    "matrix_shape = np.shape(cooccurance_matrix)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-5f0777c01bb269c8",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Tests for Q5, worth 5 points\n",
    "assert isinstance(matrix_shape,tuple)\n",
    "\n",
    "### BEGIN HIDDEN TESTS\n",
    "assert matrix_shape == (3, 3)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8b1b472cf17f90ab",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q6\n",
    "Which pair has the most papers published talking about them together?\n",
    "\n",
    "* <code>A</code>: dentate gyrus with entorhinal cortex\n",
    "* <code>B</code>: dentate gyrus with subiculum\n",
    "* <code>C</code>: entorhinal cortex with subiculum\n",
    "\n",
    "Write your answer below as a new variable, <code>q6_answer</code>. So if the answer was a hypothetical option <code>D</code>, you would write:\n",
    "\n",
    "<code>q6_answer = 'D'</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-43e81e8682b5c1b2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "q6_answer = 'A'\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ade9472e1101f50e",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Tests for Q6 (worth 5 points)\n",
    "\n",
    "assert isinstance(q6_answer,str)\n",
    "\n",
    "### BEGIN HIDDEN TESTS\n",
    "assert q6_answer == 'A'\n",
    "### END HIDDEN TESTS"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
